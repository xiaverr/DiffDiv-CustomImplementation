import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple
from datasets import YooChooseDataset 
from datasets import load_yoochoose_data 
from torch.utils.data import DataLoader
from model import DiffDiv
from tqdm import tqdm
import json
from datetime import datetime
import csv
from sklearn.model_selection import train_test_split
from torch.cuda.amp import autocast, GradScaler 
import os
import re

# è¶…å‚æ•°ï¼ˆå¯æ ¹æ® YooChoose è°ƒæ•´ï¼‰
class Config:
    item_size = 0  # å°†åœ¨æ•°æ®åŠ è½½åŽè®¾ç½®
    embed_dim = 128
    hidden_dim = 16
    latent_dim = 64
    max_seq_len = 5 #15
    T = 20           # diffusion steps
    beta_min = 1e-4
    beta_max = 0.02
    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')
    weight_dir = "./weight"
    epochs = 50

def evaluate(epoch, config, model, dataloader, k=20, device='cuda'):
    model.eval()
    recalls, mrrs = [], []


    with torch.no_grad():
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}")
        for seq, target in pbar:
            seq, target = seq.to(config.device), target.to(config.device)
            #print("target sample:", target[:5]) 
            # èŽ·å–å…¨ item logits
            logits = model(seq, train=False)   # [B, num_items]

            # æŽ’é™¤ padding itemï¼ˆé€šå¸¸ item_id ä»Ž 1 å¼€å§‹ï¼‰
            # å¦‚æžœä½ çš„ target æ˜¯ 0-indexedï¼ˆå« paddingï¼‰ï¼Œéœ€ mask
            # è¿™é‡Œå‡è®¾ target âˆˆ [1, num_items]
            topk = logits.topk(k, dim=1).indices  # å¦‚æžœ logits å¯¹åº” item 1~Nï¼Œè€Œç´¢å¼•æ˜¯ 0~N-1

            # è½¬ä¸º CPU æ¯”è¾ƒ
            topk = topk.cpu()
            target = target.cpu().unsqueeze(1)  # [B, 1]

            # Recall@k
            hit = (topk == target).any(dim=1).float()
            recalls.append(hit.mean().item())

            # MRR@k
            rank = (topk == target).nonzero(as_tuple=True)[1] + 1  # rank ä»Ž 1 å¼€å§‹
            mrr = (1.0 / rank.float()).mean().item() if len(rank) > 0 else 0.0
            mrrs.append(mrr)

    return {
        'recall': sum(recalls) / len(recalls),
        'mrr': sum(mrrs) / len(mrrs)
    }

def save_checkpoint(model, epoch, save_dir="./weight"):
    """
    ä¿å­˜æ¨¡åž‹æƒé‡åˆ°æŒ‡å®šç›®å½•ã€‚
    """
    filename = f"diffdiv_epoch_{epoch:02d}.pth"
    filepath = os.path.join(save_dir, filename)
    torch.save(model.state_dict(), filepath)
    print(f"âœ… Model saved to {filepath}")

def save_config(config, path):
    if hasattr(config, '__dict__'):
        config_dict = vars(config)
    else:
        config_dict = config
    with open(path, 'w') as f:
        json.dump(config_dict, f, indent=4)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":

    config = Config()

    print(config.device.type)

    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

    # 1. åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
    sessions, item2id, id2item, num_items = load_yoochoose_data()

    train_sessions, val_sessions = train_test_split(
        sessions,
        test_size=0.1,          # 10% ä½œä¸ºéªŒè¯é›†
        random_state=42         # å¯å¤çŽ°
    )

    print(f"Train sessions: {len(train_sessions)}")
    print(f"Val sessions:   {len(val_sessions)}")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = YooChooseDataset(train_sessions, max_seq_len=20, name="Train")
    val_dataset = YooChooseDataset(val_sessions, max_seq_len=20, name="Val")   # â† éªŒè¯é›† dataset


    train_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True, num_workers=4, pin_memory=True)

    val_dataloader = DataLoader(val_dataset, batch_size=4096, shuffle=True, num_workers=4, pin_memory=True)
    
    # 3. æ‰“å°æ ·ä¾‹
    for seq, target in train_dataloader:
        print("seq shape:", seq.shape)      # [B, 20]
        print("target shape:", target.shape) # [B]
        print("Sample seq:", seq[0])
        print("Sample target:", target[0])
        break

    
    config.item_size = num_items + 1  # +1 for padding idx 0

    model = DiffDiv(config).to(config.device)

    all_files = []
    cur_epoch = 0
    for root, dirs, filenames in os.walk(config.weight_dir):
        for filename in filenames:
            all_files.append(os.path.join(root, filename))
    if len(all_files):
        target_weight = sorted(all_files)[-1]
        model.load_state_dict(torch.load(target_weight, map_location=config.device.type))
        match = re.search(r'\d+', target_weight)
        if match:
            num_str = match.group(0)
            cur_epoch = int(num_str) + 1
    print(f"å°†ä»Žepoch:${cur_epoch}å¼€å§‹è®­ç»ƒ!")

    val_metrics = evaluate(1, config, model, val_dataloader, k=20)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    os.makedirs(config.weight_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    exp_dir = f"experiments/run_{timestamp}"
    os.makedirs(exp_dir, exist_ok=True)
    print(f"ðŸ“ Experiment directory: {exp_dir}")

    save_config(config, os.path.join(exp_dir, "config.json"))


    log_path = os.path.join(exp_dir, "train_log.csv")
    with open(log_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_loss", "val_recall@20", "val_mrr@20"])

    best_recall = 0.0

    use_amp = (config.device.type == 'cuda:1')
    if use_amp:
        scaler = GradScaler()
    

    for epoch in range(cur_epoch, config.epochs):
        model.train()
        total_loss = 0.0
        pbar = tqdm(train_dataloader, desc=f"Epoch {epoch+1}")
        for seq, target in pbar:
            seq, target = seq.to(config.device), target.to(config.device)

            optimizer.zero_grad()
            with autocast():
                loss, mse, kld = model(seq, target, train=True)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()  # æ›´æ–°ç¼©æ”¾å› å­
    
            pbar.set_postfix({'loss': f"{loss.item():.9f}"})  # æ˜¾ç¤º 6 ä½å°æ•°
            total_loss += loss.item()
            
        avg_train_loss = total_loss / len(train_dataloader)
        save_checkpoint(model, epoch + 1)

        model.eval()
        val_metrics = evaluate(epoch, config, model, val_dataloader, k=20)
        recall20 = val_metrics['recall']
        mrr20 = val_metrics['mrr']

         # --- ä¿å­˜æœ€ä½³æ¨¡åž‹ ---
        if recall20 > best_recall:
            best_recall = recall20
            torch.save(model.state_dict(), os.path.join(exp_dir, "model_best.pt"))

        # --- å†™å…¥æ—¥å¿— ---
        with open(log_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([epoch + 1, f"{avg_train_loss:.9f}", f"{recall20:.9f}", f"{mrr20:.9f}"])

        print(f"âœ… Epoch {epoch+1} | Train Loss: {avg_train_loss:.9f} | "
            f"Val Recall@20: {recall20:.9f} | Val MRR@20: {mrr20:.9f}")

        
            

    
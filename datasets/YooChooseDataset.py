import os
import pandas as pd
from collections import Counter
from torch.utils.data import Dataset, DataLoader
import torch
from collections import Counter, defaultdict
import pickle


class YooChooseDataset(Dataset):
    def __init__(self, sessions, max_seq_len=20, name="Train"):
        """
        sessions: List[List[int]], æ¯ä¸ªå­åˆ—è¡¨æ˜¯ [i1, i2, ..., iN]
        æˆ‘ä»¬å°†æ„é€ æ ·æœ¬ï¼šhistory = [i1, ..., i_{k}], target = i_{k+1}ï¼Œk >= 1
        """
        self.samples = []
        self.max_seq_len = max_seq_len
        
        for sess in sessions:
            if len(sess) < 2:
                continue
            # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ (history, next_item) å¯¹
            for i in range(1, len(sess)):
                history = sess[:i]
                target = sess[i]
                # æˆªæ–­é•¿å†å²
                if len(history) > max_seq_len:
                    history = history[-max_seq_len:]
                self.samples.append((history, target))
        
        print(f"Total {name} samples: {len(self.samples)}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        history, target = self.samples[idx]
        # padding to max_seq_len
        padded_history = [0] * (self.max_seq_len - len(history)) + history
        return torch.tensor(padded_history, dtype=torch.long), torch.tensor(target, dtype=torch.long)


def load_yoochoose_data(
    data_path="../1/yoochoose-clicks.dat",
    cache_path="data/yoochoose_processed.pkl",  # ç¼“å­˜è·¯å¾„
    min_item_freq=5,
    min_session_length=2,
    sample_frac=None  # å¯é€‰ï¼šç”¨äºå¿«é€Ÿè°ƒè¯•ï¼ˆå¦‚ 0.01ï¼‰
):
    """
    åŠ è½½å¹¶é¢„å¤„ç† YooChoose æ•°æ®ï¼Œæ”¯æŒç¼“å­˜åŠ é€Ÿã€‚
    """
    # å¦‚æœç¼“å­˜å­˜åœ¨ï¼Œç›´æ¥åŠ è½½
    if cache_path and os.path.exists(cache_path):
        print(f"ğŸ“¦ Loading processed data from cache: {cache_path}")
        with open(cache_path, "rb") as f:
            return pickle.load(f)

    # ===== å¦åˆ™ï¼Œä»å¤´å¤„ç† =====
    print("ğŸ”„ Processing raw data (this may take a few minutes)...")

    # 1. åŠ è½½åŸå§‹æ•°æ®
    df = pd.read_csv(
        data_path,
        names=["session_id", "timestamp", "item_id", "category"],
        dtype={"session_id": int, "item_id": int}
    )

    # 2. å¯é€‰ï¼šé‡‡æ ·ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    if sample_frac is not None:
        unique_sessions = df["session_id"].unique()
        sampled_sessions = pd.Series(unique_sessions).sample(frac=sample_frac, random_state=42)
        df = df[df["session_id"].isin(sampled_sessions)]

    # 3. è¿‡æ»¤çŸ­ä¼šè¯
    session_lengths = df.groupby("session_id").size()
    valid_sessions = session_lengths[session_lengths >= min_session_length].index
    df = df[df["session_id"].isin(valid_sessions)]

    # 4. è¿‡æ»¤ä½é¢‘ç‰©å“
    item_counter = Counter(df["item_id"])
    valid_items = {item for item, cnt in item_counter.items() if cnt >= min_item_freq}
    df = df[df["item_id"].isin(valid_items)]

    # 5. æ„å»º item2id æ˜ å°„ï¼ˆID ä» 1 å¼€å§‹ï¼Œ0 ä¿ç•™ç»™ paddingï¼‰
    item2id = {item: idx + 1 for idx, item in enumerate(sorted(valid_items))}
    id2item = {idx + 1: item for item, idx in item2id.items()}
    num_items = len(item2id)

    # 6. è½¬æ¢ item_id å¹¶æŒ‰ session åˆ†ç»„
    df["item_id"] = df["item_id"].map(item2id)
    sessions = df.groupby("session_id")["item_id"].apply(list).tolist()

    # 7. ä¿å­˜ç¼“å­˜ï¼ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
    if cache_path:
        os.makedirs(os.path.dirname(cache_path), exist_ok=True)
        with open(cache_path, "wb") as f:
            pickle.dump((sessions, item2id, id2item, num_items), f)
        print(f"ğŸ’¾ Cached processed data to: {cache_path}")

    return sessions, item2id, id2item, num_items